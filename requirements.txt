# AI
# torch>=2.0.0
transformers>=4.36.0
huggingface_hub
pillow>=9.0.0
numpy
bitsandbytes
auto-gptq
optimum
gptqmodel
sentence-transformers
faiss-cpu
langchain== 0.3.24
langchain-community==0.3.23
langchain_huggingface==0.1.2
openai==1.76.0 
pydantic
einops

# backend
fastapi
uvicorn

# frontend
gradio
requests

#jupyter
ipykernel